{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise with Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an excerpt of what I've been trying to do with a large amount of weather data that is not stored in an intuitive format. <br> \n",
    "The main goals of sorting through the dataset are: <br>\n",
    "\n",
    "1. Read in all the files, which include several weather stations sites and years.\n",
    "2. Pick out hourly temperature and precipitation from raw data.\n",
    "3. Store temperature and precipitation information in separate dataframe.\n",
    "4. Identify gap size in temperature & precipitation data.\n",
    "5. Select site-years that have acceptable gaps that have both temperature and precipitaiton data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some more info on the weather dataset:\n",
    "- The data is too big to put on github! Please find a subset of the data [here](https://drive.google.com/open?id=1JwjLBBS8IqNSriNKN6-BiCb5HpTe3kss).\n",
    "- NOAA maintains this dataset in the Integrated Surface Hourly (ISH) database\n",
    "- Raw data can be downloaded [here](ftp://ftp.ncdc.noaa.gov/pub/data/noaa/) if anyone might be interested.\n",
    "- The data is recorded hourly at weather stations across the US, and the information is stored in a special format called the ASCII character format.\n",
    "- Each data file records information for a particular weather station for the whole year, and each line of text within the data includes lots of information recorded on a hourly timestep, so the file will include 24*365 = 8760 lines of data if not a leap year. <br>\n",
    "There are three parts within the data that have relevant information to extract (refer to \"ISH_Manual.pdf\" included in folder:\n",
    "\n",
    "> 1. The control data section (p.4): <br>\n",
    "In here you can find timestamps, and weather station info\n",
    "> 2. The mandatory data section (p.7 & p.9): <br>\n",
    "You will find temperature data here\n",
    "> 3. The additional data section (p.12): <br>\n",
    "You will find precipitation data here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple things to think about:\n",
    "\n",
    "- This is code I put together when I just started transitioning into python (and still am!). I imagnie it has room for lots of improvement. Feel free to work with it and see what other ideas you come up with!\n",
    "- What are some good practices when wrangling data?\n",
    "- The code is slow : / <br> In reality, I have data from ~200-273 sites to process from year 1961-1990. Are there ways to make this process faster?\n",
    "- Data management?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import time as ti\n",
    "# from profilestats import profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob(\"./data/1961/*\") # make sure to update this to wherever you put your data.\n",
    "                                                     # refer to the glob tutorial EL put togehter for more info on glob: \n",
    "                                                     # \"exercise_geo_plotting/TUTORIAL_glob.ipynb\n",
    "        \n",
    "# for j in file_list[0:1]:  \n",
    "df = pd.read_csv(file_list[0], sep='\\t', header=None, squeeze=True, encoding=\"latin1\")       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read in individual weather files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The timestamp way, code takes:       0.6104340553283691  seconds to run\n",
      "The list operation way, code takes:  0.06109285354614258  seconds to run\n",
      "The original format: \n",
      "[Timestamp('1961-01-01 00:00:00'), Timestamp('1961-01-01 01:00:00'), Timestamp('1961-01-01 02:00:00')]\n",
      "The new format: \n",
      "DatetimeIndex(['1961-01-01 00:00:00', '1961-01-01 01:00:00',\n",
      "               '1961-01-01 02:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n"
     ]
    }
   ],
   "source": [
    "# Speed code up 8 times by not storing list of individual timestamps, but to store it as a Datetime vector\n",
    "\n",
    "t0 = ti.time()\n",
    "timeStampList = list()\n",
    "for k in range(5000):\n",
    "    timeStamp = pd.to_datetime(df[k][15:27], format=\"%Y%m%d%H%M\")\n",
    "    timeStampList.append(timeStamp)\n",
    "print('The timestamp way, code takes:      ', ti.time()-t0, ' seconds to run')\n",
    "               \n",
    "               \n",
    "t0 = ti.time()\n",
    "timeList = list()\n",
    "for k in range(5000):\n",
    "    timeList.append( df[k][15:27])\n",
    "tVector = pd.to_datetime(timeList, format=\"%Y%m%d%H%M\" )  \n",
    "print('The list operation way, code takes: ', ti.time()-t0, ' seconds to run')\n",
    "               \n",
    "print('The original format: ')\n",
    "print( timeStampList [0:3])\n",
    "print('The new format: ')\n",
    "print(tVector[0:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original way:  0.0860598087310791\n",
      "New way:  0.08506226539611816\n"
     ]
    }
   ],
   "source": [
    "# same speed, but shorter code by initializing list\n",
    "\n",
    "for j in file_list[0:1]:  \n",
    "    df = pd.read_csv(j, sep='\\t', header=None, squeeze=True, encoding=\"latin1\")        \n",
    "    lines = np.arange(df.shape[0])        \n",
    "    timeList = list()\n",
    "    temp = list()\n",
    "    precip = list() \n",
    "    temp2 = np.full( df.shape[0], np.nan)\n",
    "    precip2 = np.full( df.shape[0], np.nan)\n",
    "    \n",
    "    t0 = ti.time()\n",
    "    for k in lines:   \n",
    "        precip_pos = df[k].find(\"AA1\")        \n",
    "        if precip_pos == -1:\n",
    "            precip.append(\"NaN\")\n",
    "        elif int(df[k][precip_pos+5:precip_pos+9]) == 9999:\n",
    "            precip.append(\"NaN\")\n",
    "        else:\n",
    "            precip.append(int(df[k][precip_pos+5:precip_pos+9]))\n",
    "    print( 'original way: ',ti.time() - t0)       \n",
    "    \n",
    "    t0 = ti.time()\n",
    "    for k in lines:  \n",
    "        precip_pos = df[k].find(\"AA1\")           \n",
    "        if  not(precip_pos == -1)  and  not(int(df[k][precip_pos+5:precip_pos+9]) == 9999):\n",
    "            precip2[k] =  int(df[k][precip_pos+5:precip_pos+9]) \n",
    "    print( 'New way: ',ti.time() - t0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime new code:  58.46745038032532\n",
      "old runtime is about 200? Not sure because I had an error\n"
     ]
    }
   ],
   "source": [
    "# Note: this code will take a couple minutes to finish running\n",
    "\n",
    "t0 = ti.time()\n",
    "years = np.arange(1961,1966) # years of data \n",
    "# years = np.arange(1961,1962) # years of data \n",
    "df_temp_all = pd.DataFrame() # setting up an empty dataframe to store final info\n",
    "df_precip_all = pd.DataFrame() # same for precip \n",
    " \n",
    "for i in years:\n",
    "    file_list = glob.glob(\"./data/\" + str(i) + \"/*\") # make sure to update this to wherever you put your data.\n",
    "                                                     # refer to the glob tutorial EL put togehter for more info on glob: \n",
    "                                                     # \"exercise_geo_plotting/TUTORIAL_glob.ipynb\n",
    "    timepoints = pd.date_range(start = str(i) + \"-01-01\", \n",
    "                               end = str(i) + \"-12-31 23:00:00\", freq = \"H\")\n",
    "    df_temp = pd.DataFrame(index=timepoints)\n",
    "    df_precip = pd.DataFrame(index=timepoints)  \n",
    "    \n",
    "    for j in file_list:  \n",
    "        df = pd.read_csv(j, sep='\\t', header=None, squeeze=True, encoding=\"latin1\")         \n",
    "        timeList = list() \n",
    "        temp = np.full( df.shape[0], np.nan)\n",
    "        precip  = np.full( df.shape[0], np.nan )\n",
    "                          \n",
    "        for k in np.arange(df.shape[0]):\n",
    "            # time append \n",
    "            timeList.append(df[k][15:27])\n",
    "            # temp \n",
    "            if ~(int(df[k][87:92]) == 9999): \n",
    "                temp[k] = int(df[k][87:92])/10 \n",
    "            # precip store\n",
    "            p_pos = df[k].find(\"AA1\")        \n",
    "            if  not(p_pos == -1)  and  not(int(df[k][p_pos+5:p_pos+9]) == 9999):\n",
    "                precip[k] =  int(df[k][p_pos+5:p_pos+9])   \n",
    "                \n",
    "        timeDate =  pd.to_datetime(timeList, format=\"%Y%m%d%H%M\" ) \n",
    "        \n",
    "        WBAN_id = j.split(\"/\")[-1][7:12] # weather station site ID\n",
    "        df_t = pd.DataFrame({WBAN_id: temp }, index=timeDate)  \n",
    "        df_t = df_t[~df_t.index.duplicated()] # some sites have data records on sub-hourly time scale\n",
    "                                              # but I only want hourly data\n",
    "        df_temp = pd.concat([df_temp, df_t], axis= 1, \n",
    "                            join_axes=[df_temp.index], sort=False) \n",
    "        \n",
    "        df_p = pd.DataFrame({WBAN_id:precip}, index=timeDate)\n",
    "        df_p = df_p[~df_p.index.duplicated()]\n",
    "        df_precip = pd.concat([df_precip, df_p], axis= 1, \n",
    "                              join_axes=[df_precip.index], sort=False)\n",
    "        \n",
    "    timepoints = pd.date_range(start = str(i) + \"-01-01\", \n",
    "                               end = str(i) + \"-12-31 23:00:00\", freq = \"H\")\n",
    "    df_temp = pd.DataFrame(index=timepoints)\n",
    "    df_precip = pd.DataFrame(index=timepoints)  \n",
    "                          \n",
    "    frames_temp = [df_temp_all, df_temp]\n",
    "    df_temp_all = pd.concat(frames_temp, sort=False)\n",
    "    \n",
    "    frames_precip = [df_precip_all, df_precip]\n",
    "    df_precip_all = pd.concat(frames_precip, sort=False)\n",
    "    \n",
    "print('runtime new code: ', ti.time()-t0)\n",
    "print('old runtime is about 200? Not sure because I had an error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
