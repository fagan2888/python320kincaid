{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise with Data Wrangling\n",
    "\n",
    "### Things I did to make the code faster\n",
    "- Use `read_fwf` instead of `read_csv`.\n",
    "- I got rid of all the `for` loops except for one (`for` loops are slow in Python).  \n",
    "- I check the data for gaps *before* analyzing it and adding it to the master dataframe.\n",
    "- The entire code now runs in **XX minutes XX seconds** (original code runs in **XX minutes XX seconds** on my PC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "\n",
    "fnames = glob.glob(\"./weafiles/*/*\")\n",
    "\n",
    "# list of breakpoints and column names from ISH_Manual.PDF\n",
    "colnames = [\"time\", \"M_D_H\", \"temp\", \"precip\"]\n",
    "colspecs = [(15,27), (19, 25), (87,91), (105, 1000000)]\n",
    "\n",
    "crit_rows = 3 # Maximum allowed missing hours\n",
    "growseason = pd.date_range(start='2000-05-01', end='2000-10-31').strftime('%m-%d')\n",
    "\n",
    "df_temp_all = pd.DataFrame(columns=[\"time\"])\n",
    "df_precip_all = pd.DataFrame(columns=[\"time\"])\n",
    "\n",
    "for name in fnames:\n",
    "    # Read in data file with time strings preserving leading 0 characters\n",
    "    df = pd.read_fwf(name, names=colnames, colspecs=colspecs, header=None, \n",
    "                     encoding=\"latin_1\", dtype={'time': object, 'M_D_H': object})\n",
    "    \n",
    "    # Keep only rows where month and day are in growing season\n",
    "    df = df[pd.DatetimeIndex(df[\"time\"]).strftime('%m-%d').isin(growseason)]\n",
    "    \n",
    "    # Remove duplicate hours, keep only the first measurement per hour\n",
    "    df.drop_duplicates(subset=\"M_D_H\", keep=\"first\", inplace=True)\n",
    "    \n",
    "    # Get precipitation data (or NaN if AA1 is not in extra data section)\n",
    "    df[\"precip\"] = df[df['precip'].str.find(\"AA1\")!=-1]['precip'].str.split(\"AA1\").str.get(1).str.slice(5, 8)\n",
    "    \n",
    "    # Replace placeholder 9999 with NaN values\n",
    "    df[\"temp\"].astype(str).replace({'9999': np.nan}, inplace=True)\n",
    "    \n",
    "    # If there are no gaps bigger than crit_rows, then process data\n",
    "    if df.replace(method=\"ffill\", limit=crit_rows).iloc[crit_rows:].isnull().sum().sum() == 0:\n",
    "        # Get the year and site name from the filename\n",
    "        year_site = name.split(\"-\")[-1]+\"_\"+name.split(\"-\")[-2]    \n",
    "        \n",
    "        # Rename the precipitation and temperature data by year and ID\n",
    "        temp = pd.DataFrame({year_site: df[\"temp\"].astype(float), \"time\": df[\"time\"].astype(int)})\n",
    "        precip = pd.DataFrame({year_site: df[\"precip\"].astype(float), \"time\": df[\"time\"].astype(int)})\n",
    "        \n",
    "        # Merge the data onto the master dataframes\n",
    "        df_temp_all = temp.merge(df_temp_all, how=\"outer\", on=\"time\", sort=False)\n",
    "        df_precip_all = precip.merge(df_precip_all, how=\"outer\", on=\"time\", sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
